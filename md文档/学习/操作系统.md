操作系统

##### CPU如何执行程序的？

###### 冯诺依曼模型

计算机基本结构为 5 个部分，分别是中央处理器（CPU）、内存、输⼊设备、输出设备、总线。

![image-20221209213839818](https://shan-edu.oss-cn-chengdu.aliyuncs.com/img/202212092138906.png)

###### 内存

程序和数据都是存储在内存，存储的区域是线性的。 

###### CPU

CPU 内部有⼀些组件，常⻅的有寄存器、控制单元和逻辑运算单元等。常⻅的寄存器种类：

 通⽤寄存器(存放数据)，

程序计数器，⽤来存储 CPU 要执⾏下⼀条指令**「所在的内存地址」**，注意不是存储了下 ⼀条要执⾏的指令，**此时指令还在内存中，程序计数器只是存储了下⼀条指令的地址**。 

指令寄存器，**⽤来存放程序计数器指向的指令，也就是指令本**身，指令被执⾏完成之前， 指令都存储在这⾥。

###### 总线

总线是**⽤于 CPU 和内存以及其他设备之间的通信**，

总线可分为 3 种： 

地址总线，⽤于指定 CPU 将要操作的内存地址； 

数据总线，⽤于读写内存的数据； 

控制总线，⽤于发送和接收信号，⽐如中断、设备复位等信号，CPU 收到信号后⾃然进 ⾏响应，这时也需要控制总线； 当 CPU 要读写内存数据的时候，⼀般需要通过两个总线： ⾸先要**通过「地址总线」来指定内存的地址； 再通过「数据总线」来传输数据**；

###### 线路位宽

数据是如何通过线路传输的呢？其实是通过操作电压，低电压表示 0，⾼压电压则表示 1。这样⼀位⼀位传输的⽅式，**称为串⾏**，下⼀个 bit 必须等待上⼀个 bit 传输完成才能进⾏传输。当然，**想⼀次多传⼀些数据，增加线路即可**，这时数据就可以**并⾏传输**。常见的总线宽度有8位、16位、32位、64位等。如果想要 CPU 操作 4G 的内存，那么 就需要 32 条地址总线，因为 2 ^ 32 = 4G 。

###### 32位CPU如何计算64位的数

 **32 位 CPU 并不 能⼀次性计算出加和两个 64 位数字的结果**，如果⽤ 32 位 CPU 去加和两个 64 位⼤⼩的数字，就需要把这 2 个 64 位的数字分成 2 个低位 32 位数字和 2 个⾼位 32 位数字来计算，先加两个低位的 32 位数字，算出进位，然后加两个⾼位的 32 位数字，最后再加上进位

###### CPU 位宽

CPU 的位宽最好不要⼩于线路位宽，⽐如 32 位 CPU 控制 40 位宽的地址总线和数据总线的话，⼯作起来就会⾮常复杂且麻烦，如果计算的数额不超过 32 位数字的情况下，32 位和 64 位 CPU 之间没什么区别的，只有 当计算超过 32 位数字的情况下，64 位的优势才能体现出来。 另外，32 位 CPU 最⼤只能操作 4GB 内存，就算你装了 8 GB 内存条，也没⽤。⽽ 64 位 CPU 寻址范围则很⼤，理论最⼤的寻址空间为 2^64 

###### 程序执⾏的基本过程

运⾏过程就是把每⼀条指令⼀步⼀步的执⾏起来， 负责执⾏指令的就是 CPU 了

1.CPU 读取「程序计数器」的值，这个值是指令的内存地址，然后 CPU 的「控制单元」操作「地址总线」指定需要访问的内存地址，接着通知内存设备准备数据，数据 准备好后通过「数据总线」将指令数据传给 CPU，CPU 收到内存传来的数据后，将这个 指令数据存⼊到「指令寄存器」

2.CPU 分析「指令寄存器」中的指令，确定指令的类型和参数，如果是计算类型 的指令，就把指令交给「逻辑运算单元」运算；如果是存储类型的指令，则交由「控制单 元」执⾏

3.CPU 执⾏完指令后，「程序计数器」的值⾃增，表示指向下⼀条指令。这个⾃ 增的⼤⼩，由 CPU 的位宽决定，⽐如 32 位的 CPU，指令是 4 个字节，需要 4 个内存地 址存放，因此「程序计数器」的值会⾃增 4

简单来说就是⼀个程序执⾏的时候，CPU 会根据程序计数器⾥的内存地址，从内存⾥⾯把需要执⾏的指令读取到指令寄存器⾥⾯执⾏，然后根据指令⻓度⾃增，开始顺序读取下⼀条指令。 CPU 从程序计数器读取指令、到执⾏、再到下⼀条指令，这个过程会不断循环，直到程序执 ⾏结束，**这个不断循环的过程被称为 CPU 的指令周期**。



![image-20221209231033248](https://shan-edu.oss-cn-chengdu.aliyuncs.com/img/202212092310331.png)

###### 存储器⾦字塔

CPU Cache 通常会分为 L1、L2、L3 三层，速度逐渐变慢，价格逐渐变低。

![image-20221210091227548](https://shan-edu.oss-cn-chengdu.aliyuncs.com/img/202212100912604.png)

在多核芯片中，必须确定缓存的位置，AMD每个核都有自己的L2缓存，Intel使用共享L2缓存。AMD这种方式需要克服多核缓存一致性的困难，而Intel这种方式需要一种更复杂的缓存控制器

###### CPU缓存一致性

![image-20221210093017233](https://shan-edu.oss-cn-chengdu.aliyuncs.com/img/202212100930273.png)

写直达 

保持内存与 Cache ⼀致性最简单的⽅式是，把数据同时写⼊内存和 Cache 中，这种⽅法称为写直达（Write Through）。

![image-20221210093230198](https://shan-edu.oss-cn-chengdu.aliyuncs.com/img/202212100932241.png)

写直达法很直观，但是问题明显，⽆论数据在不在 Cache ⾥⾯，每次写操作都会写回到内存，这样写操作将会花费⼤量的时间，⽆疑性能会受到很⼤的影响。

写回

为了要减少数据写内存的频率，就出现了写回（Write Back）的⽅法。 在写回机制中，当发⽣写操作时，新的数据仅仅被写⼊ Cache Block ⾥，然后将该Block标记为脏，只有当脏的 Cache Block「被替换」时才需要写到内存中，减少了数据写回内存的频率，这样便可以提⾼系统的性能。

![image-20221210093918013](https://shan-edu.oss-cn-chengdu.aliyuncs.com/img/202212100939046.png)

![image-20221210093935502](https://shan-edu.oss-cn-chengdu.aliyuncs.com/img/202212100939548.png)

只有在缓存不命中，同时数据对应 的 Cache 中的 Cache Block 为脏标记的情况下，才会将数据写到内存中，减少了读写内存的频率

###### 缓存⼀致性问题

例如两个核心A和B，缓存方式使用AMD的方式，即每个核心都有自己的缓存

![image-20221210094402564](https://shan-edu.oss-cn-chengdu.aliyuncs.com/img/202212100944613.png)

A核心执行i++，i=1写入自己的缓存，而此时B核心缓存中i还是为0，因此两个CPU缓存内容不一致

方案

1.写传播（Wreite Propagation）：某个 CPU 核⼼⾥的 Cache 数据更新时，必须要传播到其他核⼼的 Cache

2.事务串行化：某个 CPU 核⼼⾥对数据的操作顺序，必须在其他核⼼看起来顺序是⼀样的

![image-20221210095335653](https://shan-edu.oss-cn-chengdu.aliyuncs.com/img/202212100953693.png)

这样做到了写传播，但是各个 Cache ⾥⾯的数据还是不⼀致的

实现写传播和事务串行化的思路

1.CPU 核⼼对于 Cache 中数据的操作，需要同步给其他 CPU 核⼼； 

2.要引⼊「锁」的概念，如果两个 CPU 核⼼⾥有相同数据的 Cache，那么对于这个 Cache 数据的更新，只有拿到了「锁」，才能进⾏对应的数据更新

具体实现

###### 总线嗅探

写传播的原则就是当某个 CPU 核⼼更新了 Cache 中的数据，要把该事件⼴播通知到其他核⼼。最常⻅实现的⽅式是总线嗅探，当 A 号 CPU 核⼼修改了 L1 Cache 中 i 变量的值，通过总线把这个事件⼴播通知给其他所有的核⼼，然后每个 CPU 核⼼都会监听总线上的⼴播事件，并检查是否有相同的数据在⾃⼰的 L1 Cache ⾥⾯，如果 B 号 CPU 核 ⼼的 L1 Cache 中有该数据，那么也需要把该数据更新到⾃⼰的 L1 Cache。总线嗅探只是保证了某个 CPU 核⼼的 Cache 更新数据这个事件能被其他 CPU 核⼼知 道，**但是并不能保证事务串行化**。

###### MESI协议

Modified已修改   Exclusive独占    Shared共享    Invalidated已失效

「已修改」状态就是我们前⾯提到的脏标记，代表该 Cache Block 上的数据已经被更新过， 但是还没有写到内存⾥。「已失效」状态，表示的是这个 Cache Block ⾥的数据已经失效 了，不可以读取该状态的数据。 

「独占」和「共享」状态都代表 Cache Block ⾥的数据是⼲净的，这个时候 Cache Block ⾥的数据和内存⾥的数据⼀致。

「独占」和「共享」的区别，独占状态的时候，数据只存储在⼀个 CPU 核⼼的 Cache ⾥，⽽其他 CPU 核⼼的 Cache 没有该数据。这个时候，如果要向独占的 Cache 写数据，**就可以直接⾃由地写⼊，⽽不需要通知其他 CPU 核⼼**，因为只有你这有这个数据，就不存在缓 存⼀致性的问题了

在「独占」状态下的数据，如果有其他核⼼从内存读取了相同的数据到各⾃的 Cache ，那么这个时候，独占状态下的数据**就会变成共享状态**。 那么，「共享」状态代表着相同的数据在多个 CPU 核⼼的 Cache ⾥都有，所以当我们要更新Cache ⾥⾯的数据的时候，**不能直接修改，⽽是要先向所有的其他 CPU 核⼼⼴播⼀个请求，要求先把其他核⼼的 Cache 中对应的 Cache Line 标记为「⽆效」状态，然后再更新当 前 Cache ⾥⾯的数据**

![image-20221210102019811](https://shan-edu.oss-cn-chengdu.aliyuncs.com/img/202212101020877.png)

##### 操作系统结构

###### 内核

计算机是由各种外部硬件设备组成的，⽐如内存、cpu、硬盘等，如果每个应⽤都要和这些硬件设备对接通信协议，那这样太累了，**所以这个中间⼈就由内核来负责，让内核作为应⽤连接硬件设备的桥梁**，应⽤程序只需关⼼与内核交互，不⽤关⼼硬件的细节

![image-20221210121003993](https://shan-edu.oss-cn-chengdu.aliyuncs.com/img/202212101210059.png)

内核有哪些能力？ 

现代操作系统，内核⼀般会提供 4 个基本能⼒： 

1.管理进程、线程，决定哪个进程、线程使⽤ CPU，也就是进程调度的能⼒；

2.管理内存，决定内存的分配和回收，也就是内存管理的能⼒；

3.管理硬件设备，为进程与硬件设备之间提供通信能⼒，也就是硬件通信能⼒；

4.提供系统调⽤，如果应⽤程序要运⾏更⾼权限运⾏的服务，那么就需要有系统调⽤，它是用户程序与操作系统之间的接⼝。

内核是怎么⼯作的？

内核具有很⾼的权限，可以控制 cpu、内存、硬盘等硬件，⽽应⽤程序具有的权限很⼩，因此⼤多数操作系统，把内存分成了两个区域： 

**内核空间**，这个内存空间只有内核程序可以访问； 

**⽤户空间**，这个内存空间专⻔给应⽤程序使⽤； ⽤户空间的代码只能访问⼀个局部的内存空间，⽽内核空间的代码可以访问所有内存空间。 因此，当程序使⽤⽤户空间时，我们**常说该程序在⽤户态执⾏，⽽当程序使内核空间时，程 序则在内核态执⾏。** 应⽤程序如果需要**进⼊内核空间，就需要通过系统调⽤，**下⾯来看看系统调⽤的过程：

![image-20221210121320757](https://shan-edu.oss-cn-chengdu.aliyuncs.com/img/202212101213799.png)

内核程序执⾏在内核态，⽤户程序执⾏在⽤户态。当**应⽤程序使⽤系统调⽤时，会产⽣⼀个中断。发⽣中断后， CPU 会中断当前在执⾏的⽤户程序，转⽽跳转到中断处理程序，也就是 开始执⾏内核程序**。内核处理完后，主动触发中断，把 CPU 执⾏权限交回给⽤户程序，回到 ⽤户态继续⼯作。

##### 虚拟内存

操作系统引⼊了虚拟内存，进程持有的虚拟地址会通过 CPU 芯⽚中的内存管理单元 （MMU）的映射关系，来转换成物理地址，然后再通过物理地址访问内存

![image-20221210122143846](https://shan-edu.oss-cn-chengdu.aliyuncs.com/img/202212101221901.png)

###### 操作系统是如何管理虚拟地址与物理地址之间的关系？

 主要有两种⽅式，分别是**内存分段和内存分⻚**，分段是⽐较早提出的， 内存分段程序是由若⼲个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。不同的段 是有不同的属性的，所以就⽤分段（Segmentation）的形式把这些段分离出来。 

分段机制下，虚拟地址和物理地址是如何映射的？ 分段机制下的虚拟地址由两部分组成，段选择⼦和段内偏移量。



分段优缺点：解决了程序本身不需要关⼼具体的物理内存地址的问题，缺点： 内存碎⽚的问题。 内存交换的效率低



###### 内存分页

分段的好处就是能产⽣连续的内存空间，但是会出现内存碎⽚和内存交换的空间太⼤的问 题。

分⻚是把整个虚拟和物理内存空间切成⼀段段固定尺⼨的⼤⼩。这样⼀个连续并且尺⼨固定 的内存空间，我们叫⻚（Page）。在 Linux 下，每⼀⻚的⼤⼩为 4KB 。

![image-20221211213952518](https://shan-edu.oss-cn-chengdu.aliyuncs.com/img/202212112139567.png)

**⻚表是存储在内存**⾥的，内存管理单元 （MMU）就做将虚拟内存地址转换成物理地址的⼯ 作。 **⽽当进程访问的虚拟地址在⻚表中查不到时，系统会产⽣⼀个缺⻚异常**，进⼊系统内核空间 分配物理内存、更新进程⻚表，最后再返回⽤户空间，恢复进程的运⾏。

采⽤了分⻚，那么释放的内存都是以⻚为单位释放的，也就不会产 ⽣⽆法给进程使⽤的⼩内存。

如果内存空间不够，操作系统会把其他正在运⾏的进程中的「最近没被使⽤」的内存⻚⾯给 释放掉，也就是暂时写在硬盘上，称为换出（Swap Out）。⼀旦需要的时候，再加载进来， 称为换⼊（Swap In）。所以，⼀次性写⼊磁盘的也只有少数的⼀个⻚或者⼏个⻚，不会花太 多时间，内存交换的效率就相对⽐较⾼。

![image-20221211214148577](https://shan-edu.oss-cn-chengdu.aliyuncs.com/img/202212112141612.png)

分⻚的⽅式使得我们在加载程序的时候，不再需要⼀次性都把程序加载到物理 内存中。我们完全可以在进⾏虚拟内存和物理内存的⻚之间的映射之后，并不真的把⻚加载 到物理内存⾥，⽽是只有在程序运⾏中，需要⽤到对应虚拟内存⻚⾥⾯的指令和数据时，再 加载到物理内存⾥⾯去。

//todo



总结

为了在多进程环境下，使得进程之间的内存地址不受影响，相互隔离，于是操作系统就为每 个进程独⽴分配⼀套虚拟地址空间，每个程序只关⼼⾃⼰的虚拟地址就可以，实际上⼤家的 虚拟地址都是⼀样的，但分布到物理地址内存是不⼀样的。

作为程序，也不⽤关⼼物理地址，每个进程都有⾃⼰的虚拟空间，⽽物理内存只有⼀个，所以当启⽤了⼤量的进程，物理内存必然会很紧张，于是操作系统会通过内存交换技术，把不常使⽤的内存暂时存放到硬盘（换 出），在需要的时候再装载回物理内存（换⼊）。 

那既然有了虚拟地址空间，那必然要把虚拟地址「映射」到物理地址，这个事情通常由操作 系统来维护。 那么对于虚拟地址与物理地址的映射关系，可以有**分段和分⻚**的⽅式，同时两者结合都是可以的。 内存分段是根据程序的逻辑⻆度，分成了栈段、堆段、数据段、代码段等，这样可以分离出不同属性的段，同时是⼀块连续的空间。但是每个段的⼤⼩都不是统⼀的，这就会导致内存碎⽚和内存交换效率低的问题。 

于是，就出现了内存分⻚，把虚拟空间和物理空间分成⼤⼩固定的⻚，如在 Linux 系统中， 每⼀⻚的⼤⼩为 4KB 。由于分了⻚后，就不会产⽣细⼩的内存碎⽚。同时在内存交换的时候，写⼊硬盘也就⼀个⻚或⼏个⻚，这就⼤⼤提⾼了内存交换的效率。 

为了解决简单分⻚产⽣的⻚表过⼤的问题，就有了**多级⻚表**，它解决了空间上的问 题，但这就会导致 CPU 在寻址的过程中，需要有很多层表参与，加⼤了时间上的开销。于是**根据程序的局部性原理，在 CPU 芯⽚中加⼊了 TLB，负责缓存最近常被访问的⻚表项**，⼤⼤ 提⾼了地址的转换速度。



#### 进程与线程

编写的代码只是⼀个存储在硬盘的静态⽂件，通过编译后就会⽣成⼆进制可执⾏⽂件， 当我们运⾏这个可执⾏⽂件后，它会被装载到内存中，接着 CPU 会执⾏程序中的每⼀条指令，那么这个运⾏中的程序，就被称为「进程」（Process）。

![image-20221211230027190](https://shan-edu.oss-cn-chengdu.aliyuncs.com/img/202212112300225.png)

如果有⼤量处于阻塞状态的进程，进程可能会占⽤着物理内存空间，显然不是我们所希望 的，毕竟物理内存空间是有限的，被阻塞状态的进程占⽤着物理内存就⼀种浪费物理内存的 ⾏为。 所以，在虚拟内存管理的操作系统中，通常会**把阻塞状态的进程的物理内存空间换出到硬 盘，等需要再次运⾏的时候，再从硬盘换⼊到物理内存。**

那么，就需要⼀个新的状态，来描述进程没有占⽤实际的物理内存空间的情况，这个状态就 是挂起状态。这跟阻塞状态是不⼀样，阻塞状态是等待某个事件的返回。

挂起状态可以分为两种： 

阻塞挂起状态：进程在外存（硬盘）并等待某个事件的出现；

就绪挂起状态：进程在外存（硬盘），但只要进⼊内存，即刻⽴刻运⾏；

![image-20221211230336230](https://shan-edu.oss-cn-chengdu.aliyuncs.com/img/202212112303276.png)

导致进程挂起的原因不只是因为进程所使⽤的内存空间不在物理内存，还包括如下情况： 通过 sleep 让进程间歇性挂起，其⼯作原理是设置⼀个定时器，到期后唤醒进程。 ⽤户希望挂起⼀个程序的执⾏，⽐如在 Linux 中⽤ Ctrl+Z 挂起进程；

##### 进程的控制结构

在操作系统中，是⽤进程控制块（process control block，PCB）数据结构来描述进程的。PCB 是进程存在的唯⼀标识，这意味着⼀个进程的存在，必然会有⼀个 PCB，如果进程消失 了，那么 PCB 也会随之消失。

PCB包含的信息：

​	进程标识符：标识各个进程，每个进程都有⼀个并且唯⼀的标识符； 

​	⽤户标识符：进程归属的⽤户，⽤户标识符主要为共享和保护服务； 

​	进程控制和管理信息： 进程当前状态，如 new、ready、running、waiting 或 blocked 等；

​	 进程优先级：进程抢占 CPU 时的优先级； 

​	资源分配清单： 有关内存地址空间或虚拟地址空间的信息，所打开⽂件的列表和所使⽤的 I/O 设备信息。

​	CPU 相关信息： CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中，以便进程重新执⾏时，能从断点处继续执⾏

##### PCB 是如何组织的呢？

通常是通过链表的⽅式进⾏组织，把具有**相同状态的进程链在⼀起，组成各种队列**。⽐如： 将所有处于就绪状态的进程链在⼀起，称为**就绪队列**； 把所有因等待某事件⽽处于等待状态的进程链在⼀起就组成各种**阻塞队列**； 另外，对于运⾏队列在单核 CPU 系统中则只有⼀个运⾏指针了，因为单核 CPU 在某个 时间，只能运⾏⼀个程序。

##### 进程上下文切换

 进程是由内核管理和调度的，所以进程的切换**只能发⽣在内核态**。 所以，进程的上下⽂切换不仅**包含了虚拟内存、栈、全局变量等⽤户空间的资源，还包括了 内核堆栈、寄存器等内核空间的资源。 通常，会把交换的信息保存在进程的 PCB，当要运⾏另外⼀个进程的时候，我们需要从这个 进程的 PCB 取出上下⽂，然后恢复到 CPU 中**，这使得这个进程可以继续执⾏

###### 进程上下⽂切换的场景

某个进程的时间⽚耗尽了，进程就从运⾏状态变为就绪状态，系统从就绪队列选择另外⼀个进程运⾏；

进程在系统资源不⾜（⽐如内存不⾜）时，要等到资源满⾜后才可以运⾏，这个时候进程也会被挂起，并由系统调度其他进程运⾏； 

当进程通过睡眠函数 sleep 这样的⽅法将⾃⼰主动挂起时，⾃然也会重新调度；

 当有优先级更⾼的进程运⾏时，为了保证⾼优先级进程的运⾏，当前进程会被挂起，由⾼优先级进程来运⾏；

 发⽣硬件中断时，CPU 上的进程会被中断挂起，转⽽执⾏内核中的中断服务程序；

###### 线程

多进程的问题：

进程之间如何通信，共享数据？ 

维护进程的系统开销较⼤，如创建进程时，分配资源、建⽴ PCB；终⽌进程时，回收资 源、撤销 PCB；进程切换时，保存当前进程的状态信息；

所以需要一种新的实体，满⾜以下特性： **1.实体之间可以并发运⾏；2. 实体之间共享相同的地址空间；**

这个新的实体，就是线程( Thread )，**线程之间可以并发运⾏且共享相同的地址空间。**



同⼀个进程内多个线程之间可以共享代码段、数据段、打开的⽂件等资源，但每个线程各⾃ 都有⼀套独⽴的寄存器和栈，这样可以**确保线程的控制流是相对独⽴的**。

![image-20221214101453067](https://shan-edu.oss-cn-chengdu.aliyuncs.com/img/202212141014143.png)

线程的优点： ⼀个进程中可以同时存在多个线程； 各个线程之间可以并发执⾏； 各个线程之间可以**共享地址空间和⽂件等资源**； 

线程的缺点： 当进程中的**⼀个线程崩溃时，会导致其所属进程的所有线程崩溃**。

线程相⽐进程能减少开销，体现在：

1. 线程的创建时间⽐进程快，因为进程在创建的过程中，还需要资源管理信息，⽐如内存管 理信息、⽂件管理信息，⽽线程在创建的过程中，不会涉及这些资源管理信息，⽽是共享 它们；
2. 线程的终⽌时间⽐进程快，因为线程释放的资源相⽐进程少很多；
3. 同⼀个进程内的线程切换⽐进程切换快，因为线程具有相同的地址空间（虚拟内存共 享），这意味着同⼀个进程的线程都具有同⼀个⻚表，那么在切换的时候不需要切换⻚表。⽽对于进程之间的切换，切换的时候要把⻚表给切换掉，⽽⻚表的切换过程开销是⽐ 较⼤的； 
4. 由于同⼀进程的各线程间共享内存和⽂件资源，那么在线程之间数据传递的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更⾼了；

###### 线程上下文切换

线程与进程最⼤的区别在于：线程是调度的基本单位，⽽进程则是资源 拥有的基本单位。 所以，所谓操作系统的任务调度，实际上的调度对象是线程，⽽进程只是给线程提供了虚拟 内存、全局变量等资源

线程和进程，我们可以这么理解： 当进程只有⼀个线程时，可以认为进程就等于线程； **当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源，这些资源在 上下⽂切换时是不需要修改的； 另外，线程也有⾃⼰的私有数据**，⽐如栈和寄存器等，这些在上下⽂切换时也是需要保存 的。

###### 线程上下⽂切换的是什么？

得看线程是不是属于同⼀个进程： **当两个线程不是属于同⼀个进程**，则切换的过程就跟进程上下⽂切换⼀样； 当两个线程是属于同⼀个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资 源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据；

###### 线程的实现

主要有三种实现方式

⽤户线程（User Thread）：在⽤户空间实现的线程，不是由内核管理的线程，是由⽤户态的线程库来完成线程的管理； 内核线程（Kernel Thread）：在内核中实现的线程，是由内核管理的线程； 

轻量级进程（LightWeight Process）：在内核中来⽀持⽤户线程； 那么，这还需要考虑⼀个问题，**⽤户线程和内核线程的对应关系**。

 ⾸先，第⼀种关系是多对⼀的关系，也就是多个⽤户线程对应同⼀个内核线程：



