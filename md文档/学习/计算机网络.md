计算机网络笔记

##### 进程通信

在操作系统中，实际进行通信的是进程而不是应用程序；当进程运行在同一个端系统上时，它们使用**进程间通信机制相互通信**；而进程间通信的规则是由端系统上的操作系统确定的。**当进程运行在不同的端系统上时，它们通过跨越计算机网络的报文相互通信**；发送进程产生报文并且向网络中发送，接收进程接收报文并对此作出响应（不响应也是一种响应）

##### 进程与计算机网络之间的接口

多数应用程序是由通信进程对组成的，运行在不同端系统上的进程对之间通过计算机网络来实现通信。所以，在应用程序进程和计算机网络之间存在一个接口，该接口被称为套接字。更为准确的说，套接字是同一台主机内应用层和运输层之间的接口。由于该套接字是建立网络应用程序的可编程接口，因此套接字也被称为应用程序和网络之间的应用编程接口（Application Programming Interface）.


应用程序开发者可以控制套接字在应用层的一切内容，但是对于运输层的相关部分，几乎没有控制权，可以做的有：

1. 选择传输层协议和设定几个传输层参数，比如最大缓存和最长传输层报文长度
2. 进程寻址

##### 运输层无法提供的服务

从可靠数据传输、吞吐量、定时、安全性等四个角度来看运输层提供的服务，我们发现，运输层无法对吞吐量和定时做出保证。但是，今天的因特网能够为时间敏感的应用提供满意的服务，尽管它并不提供任何定时或者带宽保证

### ssl与tcp与http



#####  WEB和HTTP

###### HTTP概述

HTTP（HyperText Transfer Protocol）是WEB的**应用层协议**，HTTP有两部分实现，一个客户端程序和一个服务器程序；**HTTP定义了客户和服务器进行报文交换的方法**；

Web页面是由对象组成的，一个对象是一个文件，它们通过一个URL地址进行寻址。客户和服务器交互的核心思想是客户通过HTTP请求对服务器发出对Web页面的请求报文，服务器收到该报文后将返回包含该对象的HTTP响应报文。URL地址由两部分组成：存放对象的服务器主机名和对象的路径名

**HTTP使用TCP作为它的传输层协议；HTTP客户首先发起一个与服务器的TCP连接**，需要注意的是，**服务器根据请求作出响应，但是不存储任何关于该客户的状态信息；也正因为这样，HTTP被称为无状态协议。**同时，Web使用了客户端-服务器的应用体系结构；其中web服务器总是开着的

##### HTTP报文格式：请求报文和响应报文

![img](https://img-blog.csdnimg.cn/20190324192025583.png)

请求行包含三个内容：方法类型、URL、HTTP版本；其中方法类型可为：GET、POST、PUT、DELETE、HEAD等。URL字段里可以传递请求对象的标志；

首部行包含是否在发送完响应报文后关闭TCP连接的Connection；请求的主机地址（该头部信息被Web高速缓存所要求）；浏览器版本；可接受的语言等头部信息；

在首部行之后一个空行，之后便是请求的**body(实体)**。body可以在POST方法里传递Form表单内容或者传递其它一些二进制流数据等。值得注意的是，表单也不一定必须使用POST方法。**如果使用GET方法，body为空，会显示在url中。**

##### 用户与服务器的交互：Cookie

前面提到，HTTP是无状态协议，但是Web站点为了识别用户身份或者限制用户访问的时间或者将用户访问的内容同用户身份相关联，Web站点可以使用Cookie技术；

Cookie技术包含4个组件

1. HTTP响应报文里增加一个关于Cookie的首部行；
2.   HTTP请求报文里增加一个关于Cookie的首部行；
3.   用户端系统保留一个Cookie文件，由浏览器保存维护；
4.   Web站点建立Cookie和用户身份的关联；

##### 传输层和网络层的关系

**网络层提供主机之间的逻辑通信而传输层为运行在不同主机上的应用进程提供逻辑通信**；运输层协议只工作在端系统中。在端系统中，传输层协议将来自应用进程的报文移动到网络边缘即网络层，反过来也从网络层接收这些报文段；传输层对报文段如何在网络核心传输并不做干涉；事实上中间路由器既不处理也不识别传输层加载应用层报文上的任何信息

#####  多路复用和多路分解

传输层将网络层提供的面向主机的逻辑通信扩充为面向不同应用进程的逻辑通信，并且这一过程称为多路复用和多路分解；

实际上，传输层和应用程序进程之间**通过Socket（套接字）关联，这样通过Socket就可以区别同一主机上的不同应用进程，从而传输层提供服务变为可能；传输层从同一台主机上的不同Socket接收数据的过程称为多路复用；传输层向同一台主机上的不同Socket传输数据的过程称为多路分解**；为了实现多路复用和多路分解，我们需要**标志套接字**，并将相关信息添加到报文段中，也就是**端口号**，端口号大小在0-65535之间，其中0-1023属于周知端口号

无连接的多路复用与多路分解

在创建Socket的时候，是由传输层为之分配端口号；一个UDP套接字是由一个目的IP地址和目的端口号即二元组来标志的；如果两个UDP报文段有不同的源IP地址或者源端口号，**但是有相同的目的IP和目的端口号的话，它们将通过同一个Socket到达同一个应用程序**

面向连接的多路复用与多路连接

TCP协议中的Socket是通过一个四元组来标记的：（**源IP地址，源端口号，目的IP地址，目的端口号**）；两个具有不同源IP地址或者源端口号，但有相同的目的IP地址和目的端口号的TCP报文段**将通过两个不同的Socket进入同一应用进程；这也表示，一个应用进程可以关联多个Socket，而一个Socket将只关联一个应用进程；常常，这样的对应关系是通过线程来实现的：一个进程有多个线程，而每个线程关联了一个Socket**；这样做可以提高服务器性能

##### 无连接运输：UDP

UDP是无连接的、一对多、尽最大努力交付的，它几乎没有对IP增强别的东西、但是有差错检测功能。

UDP在接收到来自Socket的数据时，UDP为该报文添加首部字段（源和目的端口号，以及其他两个小字段），然后将报文段交给网络层，网络层通过IP协议尽力地将该报文段交付，至于结果，尽力就好；当DNS客户端等待不到对该查询的响应时（有可能网络层将其丢失了）则会向其他Name Server发送查询请求，要么就通知应用程序，做不到

既然TCP提供了可靠数据传输，并且提供了拥塞控制，为什么人们还需UDP呢？事实上，有些应用很适合UDP（因为没有连接过程啊，因为不会受拥塞控制的调节啊，更自由）；UDP有以下好处：

1. 关于何时、发送什么数据的应用层控制更为精细：这是因为一旦应用程序将数据交给UDP，UDP就会打包将其发送给网络层，**不会受到传输层的调节，这在一些实时应用中比较实用**；当然，**应用程序还可以通过UDP+自主开发一些功能的模式来扩展UDP（例如可以在应用层来保证可靠性，而底层协议使用UDP）**。
2. **无需建立连接：所以就不会引入额外的时延**。
3. 无需维护连接状态：TCP为了实现可靠数据传输和拥塞控制需要在端系统中维护一些参数，这些参数包括：接收和发送的缓存、拥塞控制参数、确认号和序号；这些参数信息都是必须的；而UDP因为不建立连接，所以自然也就不需要维护这些状态，这就减少了时空开销；
4. 分组首部更小：**TCP有20字节的首部开销，而UDP只有8字节；**

##### TCP

TCP是**面向连接**的，提供**全双工服务**，并且是**点对点**的，数据从A到B的同时，也能从B到A；TCP协议**无法提供“多播**”服务，一条TCP连接只关联一个发送方和接收方（当然，发送方也是接收方），**只能一对一传输**

对于TCP建立过程中的“握手”阶段，需要明白的是，手一**共握了三次**，前两次报文段不承载“**有效负载”**，第三次握手的时候，报文段是可以装载**“有效负载”**的；

**应用程序将要发送的数据通过Socket传递给TCP，TCP将数据引导到该连接的发送缓存，发送缓存大小是在三次握手的过程中确定的；之后TCP将时不时从该缓存中拿出数据进行发送**，一个有趣的事情是，TCP规范中没有规定TCP应该在何时发送缓存里的数据，描述为“TCP应该在它方便的时候以报文段的形式发送数据”；**TCP每次可以从缓存中发送的最大数据长度称为MSS(Maximum Segment Size)**。一般来说，MSS+TCP/IP首部的长度要小于等于链路的MTU（即链路层最大帧长度Maximum Transport Unit）而**以太网和PPP的MTU都等于1500字节，TCP和IP的首部都是20字节，所以MSS一般来说为1460字节。**

TCP是面向字节流的，也就是说TCP将数据看作是一个**无结构、有序的字节流**，因此，TCP会产生粘包问题，因为TCP不能区别数据包之间的边界，粘包问题可以有很多解决方案，也可以在应用层解决，例如规定数据的前4位是数据的长度，应用层在处理时可以根据长度来判断每个分组的开始和结束位置



##### 5.1 键⼊⽹址到⽹⻚显示，期间发⽣了什么？

###### HTTP

⾸先浏览器做的第⼀步工作就是要对 URL 进⾏解析，从⽽⽣成发送给 Web 服务器的请求信息。对 URL 进行解析之后，浏览器确定了 Web 服务器和文件名，接下来就是根据这些信息来生成 HTTP 请求报文了。

###### DNS

通过浏览器解析 URL 并⽣成 HTTP 消息后，需要委托操作系统将消息发送给 Web 服务器。但在发送之前，还有⼀项⼯作需要完成，那就是查询Web服务器对应的 IP 地址，DNS通常使用迭代和轮询结合的方式进行DNS查询的

###### 协议栈

通过 DNS 获取到 IP 后，就可以把 HTTP 的传输⼯作交给操作系统中的协议栈。 协议栈的内部分为几个部分，分别承担不同的⼯作。上下关系是有⼀定的规则的，上面的部分会向下面的部分委托工作，下⾯的部分收到委托的工作并执行

![image-20221206154350687](https://shan-edu.oss-cn-chengdu.aliyuncs.com/img/202212061543824.png)

![image-20221206154411566](https://shan-edu.oss-cn-chengdu.aliyuncs.com/img/202212061544617.png)

应⽤程序（浏览器）通过调⽤ Socket 库，来委托协议栈工作。协议栈的上半部分有两块，分别是负责收发数据的
TCP 和 UDP 协议，它们两会接受应⽤层的委托执行收发数据的操作。
协议栈的下⾯⼀半是⽤ IP 协议控制⽹络包收发操作，在互联⽹上传数据时，数据会被切分成⼀块块的⽹络包，⽽
将⽹络包发送给对方的操作就是由 IP 负责的,IP 下⾯的⽹卡驱动程序负责控制**网卡硬件**，而最下面的网卡则负责完成实际的收发操作，也就是对网线中的信号执行发送和接收操作（网卡工作在物理层和数据链路层的MAC子层）。

然后是交换机和路由器，在发送过程中，源MAC地址和目的MAC地址一直在变化，而源IP和目的IP不会变化。

###### 

数据包抵达服务器后，服务器会先扒开数据包的 MAC 头部，查看是否和服务器⾃⼰的 MAC 地址符合，符合就将包收起来。 接着继续扒开数据包的 IP 头，发现 IP 地址符合，根据 IP 头中协议项，知道⾃⼰上层是 TCP 协议（TCP是17，UDP是6）。 于是，扒开 TCP 的头，⾥⾯有序列号，需要看⼀看这个序列包是不是我想要的，如果是就放⼊缓存中然后返回⼀ 个 ACK，如果不是就丢弃。TCP头部⾥⾯还有端⼝号， HTTP 的服务器正在监听这个端⼝号。 于是，服务器⾃然就知道是 HTTP 进程想要这个包，于是就将包发给 HTTP 进程。 服务器的 HTTP 进程看到，原来这个请求是要访问⼀个⻚⾯，于是就把这个⽹⻚封装在 HTTP 响应报⽂⾥。



HTTP 响应报⽂也需要加上 TCP、IP、MAC 头部，不过这次是源地址是服务器 IP 地址，⽬的地址是客户端 IP 地址。

通过网卡发送出去，客户端收到数据包后，一层一层剥开头部，一直到应用层，HTTP进程收到 HTTP 响应报⽂后，交给浏览器去渲染⻚⾯，网页就显示出来了。



###### Linux 接收⽹络包的流程

⽹卡接收到⼀个⽹络包后，会通过 DMA 技术，将⽹ 络包放⼊到 Ring Buffer，这个是⼀个环形缓冲区。当⽹卡收到⼀个⽹络包，就触发⼀个中断告诉操作系统，网络包到达了。

在⾼性能⽹络场景下，⽹络包的数量会⾮常多，那么就会触发⾮常多的中断，要知道当 CPU 收到了中断，就会停下⼿⾥的事情，⽽去处理这些⽹络包，因此效率不高。

为了解决频繁中断带来的性能开销，Linux 内核在 2.6 版本中引⼊了 NAPI 机制，它是混合「中断和轮询」的
⽅式来接收⽹络包，它的核⼼概念就是**不采⽤中断的⽅式读取数据**，⽽是⾸先采⽤中断唤醒数据接收的服务程序，
然后 poll 的⽅法来轮询数据。

当有⽹络包到达时，⽹卡发起硬件中断，于是会执⾏⽹卡硬件中断处理函数，中断处理函数处理完需要「暂时屏蔽中断」，然后唤醒「软中断」来轮询处理数据，直到没有新数据时才恢复中断，这样⼀次中断处理多个⽹络包，于是就可以降低⽹卡中断带来的性能开销。



软中断会从 Ring Buffer 中**拷⻉数据到内核 struct sk_buff 缓冲区中**，从⽽可以作为⼀ 个⽹络包交给⽹络协议栈进⾏逐层处理。 ⾸先，会先进⼊到**⽹络接⼝层**，在这⼀层会检查报⽂的合法性，如果不合法则丢弃，**合法则会找出该⽹络包的上层 协议的类型，⽐如是 IPv4，还是 IPv6，接着再去掉帧头和帧尾，然后交给⽹络层**。 到了⽹络层，则取出 IP 包，**判断⽹络包下⼀步的⾛向，⽐如是交给上层处理还是转发出去**。当确认这个⽹络包要 发送给本机后，就会从 IP 头⾥看看上⼀层协议的类型是 TCP 还是 UDP，接着去掉 IP 头，然后交给传输层。 **传输层取出 TCP 头或 UDP 头**，根据四元组「源 IP、源端⼝、⽬的 IP、⽬的端⼝」 作为标识，**找出对应的 Socket，并把数据拷⻉到 Socket 的接收缓冲区。 最后，应⽤层程序调⽤ Socket 接⼝，从内核的 Socket 接收缓冲区读取新到来的数据到应⽤层**。 ⾄此，⼀个⽹络包的接收过程就已经结束了

![image-20221206235236640](https://shan-edu.oss-cn-chengdu.aliyuncs.com/img/202212062352779.png)

###### Linux 发送⽹络包的流程

应⽤程序会调⽤ Socket 发送数据包的接⼝，由于这个是系统调⽤，**所以会从⽤户态陷⼊到内核态中的 Socket 层，Socket 层会将应⽤层数据拷⻉到 Socket 发送缓冲区中**。 接下来，⽹络协议栈从 Socket 发送缓冲区中取出数据包，并按照 TCP/IP 协议栈从上到下逐层处理。

如果使⽤的是 TCP 传输协议发送数据，那么会在传输层增加 TCP 包头，然后交给⽹络层，⽹络层会给数据包增加 IP 包，然后通过查询路由表确认下⼀跳的 IP，并按照 MTU ⼤⼩进⾏分⽚。 分⽚后的⽹络包，就会被送到⽹络接⼝层，在这⾥会通过 ARP 协议获得下⼀跳的 MAC 地址，然后增加帧头和帧 尾，放到发包队列中。 这⼀些准备好后，会触发软中断告诉⽹卡驱动程序，这⾥有新的⽹络包需要发送，最后驱动程序通过 DMA，从发 包队列中读取⽹络包，将其放⼊到硬件⽹卡的队列中，随后物理⽹卡再将它发送出去。

##### 面试题

###### HTTP

优点：应⽤⼴泛和跨平台、简单（头部+body）



双刃剑：无状态

+ 优点：服务器不会去记忆 HTTP 的状态，所以不需要额外的资源来记录状态信息，这能减轻服务器的
  负担

+ 缺点：既然服务器没有记忆能⼒，它在完成有关联性的操作时会⾮常麻烦。

双刃剑：明文传输，信息裸奔，不安全

缺点：

+ 通信使⽤明⽂（不加密），内容可能会被窃听
+ 不验证通信⽅的身份，因此有可能遭遇伪装
+ ⽆法证明报⽂的完整性，所以有可能已遭篡改

HTTPS怎么解决的

+ 混合加密的⽅式实现信息的机密性，解决了窃听的⻛险。 

+ 将服务器公钥放⼊到数字证书中，解决了冒充的⻛险。
+ 摘要算法的⽅式来实现完整性，它能够为数据⽣成独⼀⽆⼆的「指纹」，指纹⽤于校验数据的完整性，解决了篡改的⻛险。

HTTPS

1. HTTP 信息是明⽂传输，存在安全⻛险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP ⽹络层之间加⼊了 SSL/TLS 安全协议，使得报⽂能够加密传输。 

2. HTTP 连接建⽴相对简单， TCP 三次握⼿之后便可进⾏ HTTP 的报⽂传输。⽽ HTTPS 在 TCP 三次握⼿之后，还需进⾏ SSL/TLS 的握⼿过程，才可进⼊加密报⽂传输。 
3. HTTP 的端⼝号是 80，HTTPS 的端⼝号是 443。
4. HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。



![image-20221207100020687](https://shan-edu.oss-cn-chengdu.aliyuncs.com/img/202212071000808.png)

HTTPS 采⽤的是**对称加密和⾮对称加密结合的「混合加密」⽅式**： 在通信建⽴前采⽤⾮对称加密的⽅式交换「会话秘钥」，**后续就不再使⽤⾮对称加密。 在通信过程中全部使⽤对称加密的「会话秘钥」的⽅式加密明⽂数据**。 

采⽤「混合加密」的⽅式的原因： 对称加密只使⽤⼀个密钥，运算速度快，密钥必须保密，⽆法做到安全的密钥交换。 ⾮对称加密使⽤两个密钥：公钥和私钥，公钥可以任意分发⽽私钥保密，解决了密钥交换问题但速度慢。

##### 数字证书

客户端先向服务器端索要公钥，然后⽤公钥加密信息，服务器收到密⽂后，⽤⾃⼰的私钥解密。 这就存在些问题，如何保证公钥不被篡改和信任度？ **所以这⾥就需要借助第三⽅权威机构 CA** （数字证书认证机构），将服务器公钥放在数字证书（由数字证书认证 机构颁发）中，只要证书是可信的，公钥就是可信的。

![image-20221209192438541](https://shan-edu.oss-cn-chengdu.aliyuncs.com/img/202212091924696.png)

##### HTTPS 是如何建⽴连接的？

基本流程：

1.客户端向服务器索要并验证服务器的公钥。 

2.双⽅协商⽣产「会话秘钥」

3.双⽅采⽤「会话秘钥」进⾏加密通信。

详细流程：

1.客户端主要向服务器发送以下信息： （1）客户端⽀持的 SSL/TLS 协议版本，如 TLS 1.2 版本。 （2）客户端⽣产的随机数（ Client Random ），后⾯⽤于⽣产「会话秘钥」。 （3）客户端⽀持的密码套件列表，如 RSA 加密算法。

2.服务器收到客户端请求后，向客户端发出响应，有如下内容： （1）确认 SSL/ TLS 协议版本，如果浏览器不⽀持，则关闭加密通信。 （2）服务器⽣产的随机数（ Server Random ），后⾯⽤于⽣产「会话秘钥」。 （3）确认的密码套件列表，如 RSA 加密算法。 （4）服务器的数字证书

3.客户端收到服务器的回应之后，⾸先**通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性**。 如果证书没有问题，客户端会**从数字证书中取出服务器的公钥，然后使⽤它加密报⽂**，向服务器发送如下信息： （1）⼀个随机数，该随机数会被服务器公钥加密。 （2）**加密通信算法改变通知，表示随后的信息都将⽤「会话秘钥」加密通信**。 （3）客户端握⼿结束通知，表示客户端的握⼿阶段已经结束。这⼀项同时把之前所有内容的发⽣的数据做个摘要，⽤来供服务端校验

**上⾯第⼀项的随机数是整个握⼿阶段的第三个随机数，这样服务器和客户端就同时有三个随机数，接着就⽤双⽅协 商的加密算法，各⾃⽣成本次通信的「会话秘钥」。**

4.服务器收到客户端的第三个随机数之后，**通过协商的加密算法，计算出本次通信的「会话秘钥」**。然后，向客户端发⽣最后的信息： （1）加密通信算法改变通知，表示随后的信息都将⽤「会话秘钥」加密通信。 （2）服务器握⼿结束通知，表示服务器的握⼿阶段已经结束。这⼀项同时把之前所有内容的发⽣的数据做个摘 要，⽤来供客户端校验。

 ⾄此，整个 SSL/TLS 的握⼿阶段全部结束。接下来，**客户端与服务器进⼊加密通信，就完全是使⽤普通的 HTTP 协议，只不过⽤「会话秘钥」加密内容**。

##### HTTP/1.1、HTTP/2、HTTP/3 演变

HTTP1.1 相⽐ HTTP1.0：长连接、⽀持管道（pipeline）⽹络传输，只要第⼀个请求发出去了，不必等其回来，就可以发第⼆个请求出去，可以减少整体的响应时间。

HTTP1.1的缺点：

请求 / 响应头部（Header）未经压缩就发送，⾸部信息越多延迟越⼤。只能压缩 Body 的部分；

发送冗⻓的⾸部。每次互相发送相同的⾸部造成的浪费较多； 

服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端⼀直请求不到数据，**也就是队头阻塞；**

 没有请求优先级控制； 

请求只能从客户端开始，服务器只能被动响应

HTTP2 相⽐ HTTP1.1：

HTTP/2 协议是基于 HTTPS 的，所以 HTTP/2 的安全性也是有保障的

HTTP/2 会压缩头（Header）如果你同时发出多个请求，他们的头是⼀样的或是相似的，那么，**协议会帮你消除重复的部分。 这就是所谓的 HPACK 算法：在客户端和服务器同时维护⼀张头信息表，所有字段都会存⼊这个表，⽣成⼀个索引 号**，以后就不发送同样字段了，只发送索引号，这样就提⾼速度了。

二进制格式：HTTP/2 不再像 HTTP/1.1 ⾥的纯⽂本形式的报⽂，⽽是全⾯采⽤了⼆进制格式，头信息和数据体都是⼆进制，并 且统称为帧（frame）：头信息帧和数据帧。

![image-20221209195138208](https://shan-edu.oss-cn-chengdu.aliyuncs.com/img/202212091951255.png)

这样虽然对⼈不友好，但是对计算机⾮常友好，因为计算机只懂⼆进制，那么收到报⽂后，⽆需再将明⽂的报⽂转 成⼆进制，⽽是直接解析⼆进制报⽂，这增加了数据传输的效率。

HTTP/2 是通过**分帧**并且给每个帧打上**流**的 ID 去避免依次响应的问题，对方接收到帧之后根据 ID 拼接出流，这样就可以做到**乱序响应从而避免请求时的HTTP队首阻塞问题**



##### HTTP2

队头阻塞分TCP队头阻塞和HTTP队头阻塞，**2.0解决的是HTTP的队头阻塞，而TCP的队头阻塞仍然存在**



HTTP/2 主要的问题在于，**多个 HTTP 请求在复⽤⼀个 TCP 连接**，下层的 TCP 协议是不知道有多少个 HTTP 请求 的。所以⼀旦发⽣了丢包现象，就会触发 TCP 的重传机制，这样在⼀个 TCP 连接中的所有的 HTTP 请求都必须等 待这个丢了的包被重传回来。



##### http3

HTTP3协议解决了这些问题：

- **HTTP3基于UDP协议重新定义了连接，在QUIC层实现了无序、并发字节流的传输，解决了队头阻塞问题**（包括基于QPACK解决了动态表的队头阻塞）；
- 基于 UDP 的 QUIC 协议 **可以实现类似 TCP 的可靠性传输**。 QUIC 有⾃⼰的⼀套机制可以保证传输的可靠性的。当某个流发⽣丢包时，**只会阻塞这个流**，其他流不会受到 影响。 
- **TLS3 升级成了最新的 1.3 版本，头部压缩算法也升级成了 QPack** 。 
- HTTPS 要建⽴⼀个连接，要花费 6 次交互，先是建⽴三次握⼿，然后是 TLS/1.3 的三次握⼿。QUIC 直接把 以往的 TCP 和 TLS/1.3 的 6 次交互合并成了 3 次，减少了交互次数。